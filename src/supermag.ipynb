{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_catalog(year, station):\n",
    "    catalog = pd.read_csv(f\"D:/Capstone/data/catalog/csv/{station}_catalog_1960.csv\")\n",
    "    catalog['time'] = pd.to_datetime(catalog['time'])\n",
    "    catalog_year = catalog[catalog['time'].dt.year == year]\n",
    "    print(f\"catalog: {len(catalog_year)}\")\n",
    "    return catalog_year\n",
    "\n",
    "def open_raw_data(year):\n",
    "    print(\"opening raw data...\")\n",
    "    ds = xr.open_dataset(f\"D:/Capstone/data/geomagnetic_data/all_stations_all{year}.netcdf\", engine=\"netcdf4\")\n",
    "    print(\"raw data access success...\")\n",
    "    return ds\n",
    "    \n",
    "def prepare_raw_data(ds, station):\n",
    "    # Extract the station IDs for the first block (time step)\n",
    "    station_ids = ds['id'].isel(block=0)\n",
    "\n",
    "    ds = ds.assign_coords(station_id=('vector', station_ids.data))\n",
    "    ds = ds.swap_dims({'vector':'station_id'})\n",
    "    \n",
    "    time = pd.to_datetime({\n",
    "        'year': ds['time_yr'].values,\n",
    "        'month': ds['time_mo'].values,\n",
    "        'day': ds['time_dy'].values,\n",
    "        'hour': ds['time_hr'].values,\n",
    "        'minute': ds['time_mt'].values,\n",
    "        'second': ds['time_sc'].values\n",
    "    })\n",
    "\n",
    "    ds = ds.assign_coords(time=('block', time))\n",
    "    ds = ds.swap_dims({'block': 'time'})\n",
    "   \n",
    "    station_ds = ds.sel(station_id=(ds['station_id'] == station))\n",
    "    \n",
    "    print(f\"station ds: {station_ds.coords['station_id'].size}\")\n",
    "    # print(station_ds)\n",
    "    return station_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_to_tensor(segment, station):\n",
    "    # print(segment)\n",
    "    selected_vars = ['dbn_nez', 'dbe_nez', 'dbz_nez']\n",
    "    variable_tensors = [torch.tensor(segment[var].sel(station_id=station).values, dtype=torch.float32) for var in selected_vars]\n",
    "    final_tensor = torch.stack(variable_tensors)\n",
    "    # print(\"Shape of final tensor:\", final_tensor.shape)\n",
    "    return final_tensor\n",
    "\n",
    "def build_dataset(year, station, ds, catalog, seg_len):\n",
    "    print(\"building dataset...\")\n",
    "    pre_EQ = []\n",
    "    non_EQ = []\n",
    "    for i in range(len(catalog)):\n",
    "        # print(f\"i: {i}\")\n",
    "        current_EQ= catalog.iloc[i]\n",
    "        end_time = current_EQ['time'].tz_localize(None)\n",
    "        start_time = (current_EQ['time'] - pd.Timedelta(hours=seg_len)).tz_localize(None)\n",
    "        if i == len(catalog)-1:\n",
    "            prev_EQ_time = datetime(year, 1, 1, 0, 0, 0)\n",
    "            prev_EQ_time = pd.Timestamp(prev_EQ_time).tz_localize(None)\n",
    "        else:\n",
    "            prev_EQ = catalog.iloc[i+1]\n",
    "            prev_EQ_time = prev_EQ['time'].tz_localize(None)\n",
    "        # print(f\"start_time: {start_time}\")\n",
    "        # print(f\"prev_EQ_time: {prev_EQ_time}\")\n",
    "        while start_time >= prev_EQ_time:\n",
    "            segment = ds.sel(time=slice(start_time, end_time))\n",
    "            seg_tensor = seg_to_tensor(segment=segment, station=station)\n",
    "            if end_time == current_EQ['time'].tz_localize(None):\n",
    "                pre_EQ.append(seg_tensor)\n",
    "            else:\n",
    "                non_EQ.append(seg_tensor)\n",
    "\n",
    "            start_time -= pd.Timedelta(hours=seg_len)\n",
    "            end_time -= pd.Timedelta(hours=seg_len)\n",
    "            \n",
    "\n",
    "    print(f\"Pre EQ:{len(pre_EQ)}\")\n",
    "    # print(pre_EQ)\n",
    "    print(f\"non EQ:{len(non_EQ)}\")\n",
    "    # print(non_EQ)\n",
    "    station_directory = f\"D:\\Capstone\\data\\dataset\\{station}\"\n",
    "    os.makedirs(station_directory, exist_ok=True)\n",
    "\n",
    "    if len(pre_EQ) > 0:\n",
    "        pre_EQ_tensor = torch.stack(pre_EQ)\n",
    "        torch.save(pre_EQ_tensor, f\"D:\\Capstone\\data\\dataset\\{station}\\\\test_{year}_{station}_{seg_len}hr.pt\")\n",
    "\n",
    "    if len(non_EQ) > 0:\n",
    "        non_EQ_tensor = torch.stack(non_EQ)\n",
    "        torch.save(non_EQ_tensor, f\"D:\\Capstone\\data\\dataset\\{station}\\\\normal_{year}_{station}_{seg_len}hr.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "stations=['ANT', 'BIK', 'BLC', 'FUR', 'KAK', 'KNY', 'LMA', 'MMB', 'PBQ', 'PEL', 'SHU', 'SIT', 'TND']\n",
    "seg_len = 168\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening raw data...\n",
      "raw data access success...\n"
     ]
    }
   ],
   "source": [
    "raw_data = open_raw_data(year=year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station: ANT\n",
      "catalog: 8\n",
      "station ds: 0\n",
      "ANT not available for 2022\n",
      "\n",
      "\n",
      "station: BIK\n",
      "catalog: 8\n",
      "station ds: 0\n",
      "BIK not available for 2022\n",
      "\n",
      "\n",
      "station: BLC\n",
      "catalog: 1\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:1\n",
      "non EQ:41\n",
      "\n",
      "\n",
      "station: FUR\n",
      "catalog: 0\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:0\n",
      "non EQ:0\n",
      "\n",
      "\n",
      "station: KAK\n",
      "catalog: 62\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:17\n",
      "non EQ:7\n",
      "\n",
      "\n",
      "station: KNY\n",
      "catalog: 22\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:12\n",
      "non EQ:30\n",
      "\n",
      "\n",
      "station: LMA\n",
      "catalog: 8\n",
      "station ds: 0\n",
      "LMA not available for 2022\n",
      "\n",
      "\n",
      "station: MMB\n",
      "catalog: 12\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:9\n",
      "non EQ:33\n",
      "\n",
      "\n",
      "station: PBQ\n",
      "catalog: 0\n",
      "station ds: 0\n",
      "PBQ not available for 2022\n",
      "\n",
      "\n",
      "station: PEL\n",
      "catalog: 33\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:12\n",
      "non EQ:27\n",
      "\n",
      "\n",
      "station: SHU\n",
      "catalog: 11\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:11\n",
      "non EQ:35\n",
      "\n",
      "\n",
      "station: SIT\n",
      "catalog: 1\n",
      "station ds: 1\n",
      "building dataset...\n",
      "Pre EQ:1\n",
      "non EQ:0\n",
      "\n",
      "\n",
      "station: TND\n",
      "catalog: 67\n",
      "station ds: 0\n",
      "TND not available for 2022\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for station in stations:\n",
    "    print(f\"station: {station}\")\n",
    "    catalog = prepare_catalog(year=year, station=station)\n",
    "    ds = prepare_raw_data(ds=raw_data, station=station)\n",
    "    if ds.coords['station_id'].size != 0:\n",
    "        build_dataset(year=year, station=station, ds=ds, catalog=catalog, seg_len=seg_len)\n",
    "    else:\n",
    "        print(f\"{station} not available for {year}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
